# Metric Learning for AI Evaluation - DA5401 Data Challenge

This repository contains the winning solution for the **DA5401 End-Semester Data Challenge (2025)**. The goal was to build a metric learning model to predict the "fitness score" (0-10) of a prompt-response pair against a specific AI evaluation metric definition.

## Author 
**Name:** Nikhil Enugu

**Roll-No:** DA25M010

## ðŸ† Challenge Overview

* **Task:** Predict the semantic alignment score (0-10) between a Metric Definition and a Prompt-Response pair.
* **Metric:** Root Mean Square Error (RMSE).
* **Core Challenges:**
    * **Severe Class Imbalance:** 90% of training data had scores of 9.0 or 10.0.
    * **Covariate Shift:** Test data had a significantly lower mean score (~5.0) than training data (~9.3).
    * **Multilingual Text:** Inputs included Tamil, Hindi, and English.
    * **Missing Definitions:** Metric definitions were only provided as embeddings, not text.

## ðŸ’¡ Solution Strategy

This solution achieved a competitive RMSE by combining **Deep Metric Learning** with an aggressive **Synthetic Negative Augmentation** strategy to fix the class imbalance.

### 1. Data Engineering
* **Multilingual Embedding:** Used `intfloat/multilingual-e5-large` via `SentenceTransformer` to handle the mixed-language inputs robustly.
* **Vectorized Feature Interaction:** Instead of relying solely on raw embeddings, explicit interaction features were engineered to capture geometric relationships:
    * **Cosine Similarity** (Angle/Alignment)
    * **Euclidean Distance** (Magnitude difference)
    * **Element-wise Product** (Unnormalized interaction)
    * **Absolute Difference** (Discrepancy vector)

### 2. "The Hack": Synthetic Negative Augmentation
To solve the 90/10 class imbalance and the high-score skew, I implemented a data augmentation pipeline that generated 3 "fake" low-scoring examples for every real high-scoring example.

* **Shuffle Negatives:** Pairing a real metric embedding with a random (incorrect) text response.
* **Noise Negatives:** Adding Gaussian noise to the valid text embedding to simulate incoherent responses.
* **Metric Swap:** Pairing a valid text response with the wrong metric definition.

**Result:** This transformed the dataset distribution from a steep skew to a balanced bimodal distribution, forcing the model to learn decision boundaries for low scores.

### 3. Model Architecture: ResNet Regressor
A **Residual Neural Network (ResNet)** was selected over a standard MLP to effectively learn non-linear mappings from the interaction features.

* **Structure:** Input Projection -> 3x Residual Blocks (Linear + BatchNorm + GELU + Dropout) -> Output Head.
* **Loss Function:** `SmoothL1Loss` (Huber Loss) was used to be robust against the outliers introduced by the synthetic data generation.
* **Training:** 5-Fold Cross-Validation with Early Stopping and Learning Rate Scheduling (`ReduceLROnPlateau`).

## ðŸ“Š Performance

| Metric | Score |
| :--- | :--- |
| **Final Test RMSE** | **~1.9** |
| **Training Loss** | 0.36 |

*The final model successfully predicted a balanced distribution of scores (0-10) on the test set, overcoming the high-score bias of the training data.*

## ðŸ“‚ Repository Structure

* `final_code.ipynb`: The complete Jupyter notebook containing data loading, augmentation, training, and inference.
* `kaggle_report.pdf`: Detailed report explaining the methodology, EDA, and theoretical justification.
* `submission_resnet_optimized.csv`: The final prediction file generated by the model.
